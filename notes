- My hypothesis dat student core produce kan word van teacher factors werk baie mooi
    - Dit stabilize die training = Geen exploding gradients
- Op die oomblik lyk dit nie asof dit ideal results gee nie though
- Ek sal n ablation moet doen om te sien of ek ideal settings kan vind om tucker decomposition te gebruik
- Base case moet wees geen tucker decomposition op enige van die feature maps
- Ek gaan net een training run doen per experiment settings (nie 10 soos laas keer)
### Next step
- Factorize en parameterize vir rapid experimentation

### Gaps?
- Ek weet nogsteeds nie hoekom ek exploding gradients gekry het met die vorige TD attempts nie
- My knowledge oor hoe tucker decomposition werk is nogsteeds baie shallow

### Notes
- Ek wil vanaand op n punt wees waar ek die rapid experimentation kan doen
- Dan sal ek deur die dag more en oormore experiments queue
- Dan behoort ek donderdag of aan te kan hou hiermee of pivot na noise injection



### QUESTIONS
- Se nou net ek doen tucker decomposition en reconstruction op net een van die feature maps en gebruik die ander featuremap net soos wat hy is????
- Se nounet ek gebriuk brue force featuer map distillation maar sonder daai FT function???


#### EXEPERIMENTS WAT EK PROBABLY WIL RUN
1. brute_force_feature_map_distillation
    - sonder FT function
    - met FT function
2. tucker teacher autoencoder
    - probably so 9 levels van compression
3. XOR tucker 
    - Op teacher
        - 3 levels van compression en reconstruction, van heavy to light
        - 3 levels van compression en reconstruction, van heavy to light
4. Verskillende BETA levels???
    - Sterker BETA
    - Null BETA