{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ae6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox.models import ResNet112, ResNet56\n",
    "from toolbox.data_loader import Cifar100\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rich import print as pprint\n",
    "from tqdm import trange\n",
    "\n",
    "device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37331c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model_path = r\"toolbox/Cifar100_ResNet112.pth\"\n",
    "teacher = ResNet112(100).to(device)\n",
    "teacher.load_state_dict(torch.load(model_path, weights_only=True)[\"weights\"])\n",
    "teacher.eval()\n",
    "\n",
    "# STUDENT \n",
    "student = ResNet56(100).to(device)\n",
    "student.train()\n",
    "\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "Data = Cifar100()\n",
    "trainloader, testloader = Data.trainloader, Data.testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd6d42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abs tensor(1706.0847, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(15.9687, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(2.4207, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tl.set_backend(\"pytorch\")\n",
    "def tucker(feature_map): #expects 4d\n",
    "    batch_size, channels, height, width = feature_map.shape\n",
    "    core, factors = tl.decomposition.tucker(feature_map, rank=[batch_size, 32, 8, 8])\n",
    "    return core, factors\n",
    "\n",
    "def compute_core(feature_map, factors):\n",
    "    return tl.tenalg.multi_mode_dot(feature_map, [f.T for f in factors], modes=[0, 1, 2, 3])\n",
    "\n",
    "def FT(x):\n",
    "    return F.normalize(x.reshape(x.size(0), -1))\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    teacher_outputs = teacher(inputs)\n",
    "    student_outputs = student(inputs)\n",
    "\n",
    "    teacher_core, teacher_factors = tucker(teacher_outputs[2])\n",
    "    # student_core, student_factors = tucker(student_outputs[2])\n",
    "    student_core = compute_core(student_outputs[2], teacher_factors)\n",
    "\n",
    "    print(\"abs\", tl.norm(teacher_core - student_core))\n",
    "    loss_amount = tl.norm(FT(teacher_core) - FT(student_core))\n",
    "    print(loss_amount)\n",
    "\n",
    "    loss_amount = 125 * criterion(FT(student_core), FT(teacher_core))\n",
    "    print(loss_amount)\n",
    "    break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
